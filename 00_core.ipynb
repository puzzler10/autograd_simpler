{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing autograd from scratch\n",
    "\n",
    "> This will have both code and documentation in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from \n",
    "import numpy as np\n",
    "import autograd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are we trying to find?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to have a function we want to differentiate. This function will take in some number of variables: one, two, three... however many. If our function is called $f$, we are looking to find $df/dv$, where $v$ is one of these variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function in two variables: x and y. $$f = \\log(x^2) + y^2 + xy$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x,y):    return np.log(x**2) + y**2 + x*y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to create a function `grad` that takes `f` as an input and returns a function with its gradient wrt a variable. So for our function above, `grad` can give us the answer of either $df/dx$ or $df/dy$, depending on what variable we tell it to differentiate with respect to. Let's define `grad`, giving it dummy values for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we choose this variable? We don't do it by name, telling the function either 'x' or 'y'. Rather, we give it a number (call it `argnum`), and say, \"Differentiate `f` with respect to the `argnum`th input.\" `f` has an argument list, and `argnum` is the index of this variable list, which corresponds to the variable we are interested in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad` has a nested structure: it returns a function `gradfun` that in turn returns the gradient. Notice the use of `*args` and `**kwargs` below. This is needed in the inner function `gradfun` because a) it doesnt' know how many arguments `f` takes; b) you can choose to call those arguments either with or without keywords. If you call them without keywords, the arguments are stored in `*args`, and if you call them with keywords, the arguments are stores in `**kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args (1, 2)\n",
      "Kwargs {}\n",
      "dfdx 137.37736658799992\n",
      "Args ()\n",
      "Kwargs {'x': 13, 'y': 4}\n",
      "dfdy 21\n"
     ]
    }
   ],
   "source": [
    "def grad(f, argnum = 0): \n",
    "    \"\"\"Returns a function that finds the gradient\"\"\"\n",
    "    def gradfun(*args, **kwargs):\n",
    "        \"\"\"Returns the actual gradient \"\"\"\n",
    "        #set_trace()\n",
    "        print (\"Args\", args)\n",
    "        print (\"Kwargs\", kwargs)\n",
    "        # Dummy values. Returns correct gradient only for our function f above. \n",
    "        # Use these values until we calculate the true ones using autodiff. \n",
    "        #### remove this code once true code written\n",
    "        if   argnum == 0: return 2*x * np.log(x**2) + y  # df/dx\n",
    "        elif argnum == 1: return 2*y + x                 # df/dy\n",
    "        #### \n",
    "        # true autograd code goes here \n",
    "        ####\n",
    "    return gradfun\n",
    "# example usage\n",
    "dfdx = grad(f, argnum = 0)\n",
    "dfdy = grad(f, argnum = 1)\n",
    "print(\"dfdx\", dfdx(1,2))      # call gradient w/out keywords, values go into *args    in gradfun \n",
    "print(\"dfdy\", dfdy(x=13,y=4)) # call gradient with  keywords, values go into **kwargs in gradfun "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's our goal. We are trying to build this `grad` function properly, following the structure defined above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a computation graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you had some expression, like $ (4 \\times 5) + 2 - 4$. I'm sure you know the answer to this, but how would a computer work it out? \n",
    "\n",
    "You may remember the order of operations used to work out these expressions; I learnt the acronym [BODMAS](https://www.mathsisfun.com/operation-order-bodmas.html) to remember these. Python has its own order of operations too, governed by the hierarchy of [operator precedence](https://docs.python.org/3/reference/expressions.html#operator-precedence). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Autodifferentiation relies on the computation graph of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation graph is made up of Nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping Nodes in Boxes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boxes are used to indicate the variable you are differentiating with respect to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making VJPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backwards pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
