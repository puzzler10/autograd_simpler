{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as _np\n",
    "import types \n",
    "from functools import wraps\n",
    "\n",
    "def primitive(f, keepgrad=True): \n",
    "    @wraps(f)\n",
    "    def inner(*args, **kwargs):\n",
    "        ## Code to add operation/primitive to computation graph\n",
    "        # We need to separate out the integer/non node case. Sometimes you are adding \n",
    "        # constants to nodes. \n",
    "        def getval(o):      return o.value if type(o) == Node else o\n",
    "        if len(args):       argvals = [getval(o) for o in args]\n",
    "        else:               argvals = args\n",
    "        if len(kwargs):     kwargvals = dict([(k,getval(o)) for k,o in kwargs.items()])\n",
    "        else:               kwargvals =  kwargs\n",
    "         \n",
    "        # get parents \n",
    "        l = list(args) + list(kwargs.values())\n",
    "        parents = [o for o in l if type(o) == Node ]\n",
    "        \n",
    "        value = f(*argvals, **kwargvals)\n",
    "        print(\"add\", \"'\" + f.__name__ + \"'\", \"to graph with value\",value)\n",
    "        return Node(value, f, parents, keepgrad)\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"A node in a computation graph.\"\"\"\n",
    "    def __init__(self, value, fun, parents, keepgrad):\n",
    "        self.parents = parents\n",
    "        self.value = value\n",
    "        self.fun = fun \n",
    "        self.keepgrad = keepgrad\n",
    "        \n",
    "    def __repr__(self): \n",
    "        \"\"\"A (very) basic string representation\"\"\"\n",
    "        if self.value is None: str_val = 'None'\n",
    "        else:                  str_val = str(self.value)\n",
    "        return   \"\\n\" + \"Fun: \" + str(self.fun) +\\\n",
    "                \" Value: \"+ str_val + \\\n",
    "                \" Parents: \" + str(self.parents) \n",
    "    \n",
    "    def start_node(value = None, keepgrad=True): \n",
    "        \"\"\"A function to create an empty node to start off the graph\"\"\"\n",
    "        fun,parents = lambda x: x, []\n",
    "        return Node(value, fun, parents, keepgrad=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_namespace(old, new):\n",
    "    \"\"\"Performs triage on objects from numpy, copying them from old to new namespace. \n",
    "       old: __dict__ from original numpy\n",
    "       new: dict to copy old into \n",
    "       \"\"\"\n",
    "    # Taken from here: \n",
    "    # https://github.com/mattjj/autodidact/blob/b3b6e0c16863e6c7750b0fc067076c51f34fe271/autograd/numpy/numpy_wrapper.py#L8 \n",
    "    nograd_functions = [\n",
    "        _np.ndim, _np.shape, _np.iscomplexobj, _np.result_type, _np.zeros_like,\n",
    "        _np.ones_like, _np.floor, _np.ceil, _np.round, _np.rint, _np.around,\n",
    "        _np.fix, _np.trunc, _np.all, _np.any, _np.argmax, _np.argmin,\n",
    "        _np.argpartition, _np.argsort, _np.argwhere, _np.nonzero, _np.flatnonzero,\n",
    "        _np.count_nonzero, _np.searchsorted, _np.sign, _np.ndim, _np.shape,\n",
    "        _np.floor_divide, _np.logical_and, _np.logical_or, _np.logical_not,\n",
    "        _np.logical_xor, _np.isfinite, _np.isinf, _np.isnan, _np.isneginf,\n",
    "        _np.isposinf, _np.allclose, _np.isclose, _np.array_equal, _np.array_equiv,\n",
    "        _np.greater, _np.greater_equal, _np.less, _np.less_equal, _np.equal,\n",
    "        _np.not_equal, _np.iscomplexobj, _np.iscomplex, _np.size, _np.isscalar,\n",
    "        _np.isreal, _np.zeros_like, _np.ones_like, _np.result_type\n",
    "    ]\n",
    "    function_types = {_np.ufunc, types.FunctionType, types.BuiltinFunctionType}\n",
    "\n",
    "    for name,obj in old.items(): \n",
    "        if obj in nograd_functions:  \n",
    "            # non-differentiable functions \n",
    "            new[name] = primitive(obj, keepgrad=False)\n",
    "        elif type(obj) in function_types:  # functions with gradients \n",
    "            # differentiable functions\n",
    "            new[name] = primitive(obj)\n",
    "        else: \n",
    "            # just copy over \n",
    "            new[name] = obj\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using globals() here means we can access each np function like np.add: \n",
    "# it means it is available to the global space. \n",
    "anp = globals()\n",
    "wrap_namespace(_np.__dict__, anp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants w.r.t float data just pass though\n",
    "setattr(Node, 'ndim', property(lambda self: self.value.ndim))\n",
    "setattr(Node, 'size', property(lambda self: self.value.size))\n",
    "setattr(Node, 'dtype',property(lambda self: self.value.dtype))\n",
    "setattr(Node, 'T', property(lambda self: anp['transpose'](self)))\n",
    "setattr(Node, 'shape', property(lambda self: self.value.shape))\n",
    "setattr(Node,'__len__', lambda self, other: len(self._value))\n",
    "setattr(Node,'astype', lambda self,*args,**kwargs: anp['_astype'](self, *args, **kwargs))\n",
    "setattr(Node,'__neg__', lambda self: anp['negative'](self))\n",
    "setattr(Node,'__add__', lambda self, other: anp['add'](     self, other))\n",
    "setattr(Node,'__sub__', lambda self, other: anp['subtract'](self, other))\n",
    "setattr(Node,'__mul__', lambda self, other: anp['multiply'](self, other))\n",
    "setattr(Node,'__pow__', lambda self, other: anp['power'](self, other))\n",
    "setattr(Node,'__div__', lambda self, other: anp['divide'](  self, other))\n",
    "setattr(Node,'__mod__', lambda self, other: anp['mod'](     self, other))\n",
    "setattr(Node,'__truediv__', lambda self, other: anp['true_divide'](self, other))\n",
    "setattr(Node,'__matmul__', lambda self, other: anp['matmul'](self, other))\n",
    "setattr(Node,'__radd__', lambda self, other: anp['add'](     other, self))\n",
    "setattr(Node,'__rsub__', lambda self, other: anp['subtract'](other, self))\n",
    "setattr(Node,'__rmul__', lambda self, other: anp['multiply'](other, self))\n",
    "setattr(Node,'__rpow__', lambda self, other: anp['power'](   other, self))\n",
    "setattr(Node,'__rdiv__', lambda self, other: anp['divide'](  other, self))\n",
    "setattr(Node,'__rmod__', lambda self, other: anp['mod'](     other, self))\n",
    "setattr(Node,'__rtruediv__', lambda self, other: anp['true_divide'](other, self))\n",
    "setattr(Node,'__rmatmul__', lambda self, other: anp['matmul'](other, self))\n",
    "setattr(Node,'__eq__', lambda self, other: anp['equal'](self, other))\n",
    "setattr(Node,'__ne__', lambda self, other: anp['not_equal'](self, other))\n",
    "setattr(Node,'__gt__', lambda self, other: anp['greater'](self, other))\n",
    "setattr(Node,'__ge__', lambda self, other: anp['greater_equal'](self, other))\n",
    "setattr(Node,'__lt__', lambda self, other: anp['less'](self, other))\n",
    "setattr(Node,'__le__', lambda self, other: anp['less_equal'](self, other))\n",
    "setattr(Node,'__abs__', lambda self: anp['abs'](self))\n",
    "setattr(Node,'__hash__', lambda self: id(self))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook np_wrapping.ipynb to script\n",
      "[NbConvertApp] Writing 8366 bytes to np_wrapping.py\n"
     ]
    }
   ],
   "source": [
    "# convert to python script \n",
    "#!jupyter nbconvert --to script np_wrapping.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
